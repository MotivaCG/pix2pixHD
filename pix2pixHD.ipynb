{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pixHD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f-tEfNmWUlJR",
        "32q351TCYGOa",
        "big1f7SvaB7p",
        "NMh4tpXnHAmZ",
        "iCSsYCKXIQZ1",
        "tFDYgh1qIFFz",
        "6C31h725KWLx",
        "FTkwfWoOAUbS"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVO-LxDxs1YR"
      },
      "source": [
        "# Pix2PixHD\n",
        "\n",
        "This notebook was created by Doug Rosman, and uses code from [Doug's forked pix2pixHD repository](https://github.com/dougrosman/pix2pixHD). For a video tutorial showing how to use this notebook, visit this link here: [https://dougrosman.github.io/cvml-sp21/resources/pix2pixHD/](https://dougrosman.github.io/cvml-sp21/resources/pix2pixHD/)\n",
        "\n",
        "**Last updated: May 9, 2021, 2:00pm CST**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewD4YcUPt3Qf"
      },
      "source": [
        "## 1. Connect to a GPU Instance (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4yKFd4zJ6C"
      },
      "source": [
        "**Executing this cell will connect you to a GPU, and your 8-10 hours of free GPU time will begin.**\n",
        "\n",
        "This will show you what GPU you've been randomly given for this instance. With a Google Colab Pro account ($9.99/mo, really worth it!), you're almost always guaranteed a **P100**, with a chance at getting a **V100**.\n",
        "* **V100:** Best, (not available for free accounts)\n",
        "* **P100:** Great\n",
        "* **T4:** (untested) this likely will *not* work for training, but is great for generating.\n",
        "* **K80:** (untested) this might work for training, but it will likely be very slow. Should be just fine for generating (though slow).\n",
        "\n",
        "If you get a T4 or K80, I encourage you to terminate your session, wait 5-10 minutes, then try connecting to a GPU again. To terminate your session, at the top of your screen go to **Runtime** --> **Manage Sessions** --> **Terminate**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KisNe7y5as8J"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD-3fgfwNd8"
      },
      "source": [
        "## 2. Mount your Google Drive (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhemEUvrzTif"
      },
      "source": [
        "**Executing this cell will prompt you to mount your Google Drive.**\n",
        "\n",
        "After executing, a link will show up. Click the link and follow the directions. Select the Google Drive you wish to use, then copy and paste the authorization key into the box below, and press 'Enter' or 'Return' on your keyboard.\n",
        "\n",
        "If you have multiple Google Accounts, I recommend mounting whichever one has the most storage, since working with pix2pixHD requires a lot of storage for all your images and trained models. If you're generating images, make sure that the .pth files you want to generate from are in the Google Drive that you mount.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Id6wSjbH5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06be09b-38b3-49be-b063-9b6042647402"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DvGIfacxJL_"
      },
      "source": [
        "## 3. Install pix2pixHD repository OR change directory into repo (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdOJwnvTzbn0"
      },
      "source": [
        "**Executing this cell will either install the pix2pixHD repo into your Google Drive, or move you into the pix2pixHD repo if it already exists. This cell also installs a python dependency called _dominate_.**\n",
        "\n",
        "##### **Case 1: Installing the repo**\n",
        "If this is your first time using this notebook (or if you deleted a previously installed version of the pix2pixHD repo in you Google Drive), this cell will clone Doug Rosman's forked pix2pixHD repo into your Google Drive into a folder called 'colab-pix2pixHD'. After cloning, it will move you into the pix2pixHD folder.\n",
        "\n",
        "##### **Case 2: Moving into the repo**\n",
        "If this repo already exists in your Google drive, this cell will move you into the pix2pixHD folder so that you can execute the other cells in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQpxYVIbLja"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-pix2pixHD\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-pix2pixHD/pix2pixHD\"\n",
        "    !pip install dominate\n",
        "    !pip install -r util/requirements.txt\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-pix2pixHD\n",
        "    %cd colab-pix2pixHD\n",
        "    !git clone https://github.com/dougrosman/pix2pixHD\n",
        "    %cd pix2pixHD\n",
        "    !mkdir generated_videos\n",
        "    !pip install dominate\n",
        "    #install python requirements for Derrick Schultz' dataset-tools.py\n",
        "    #more info: https://github.com/dvschultz/dataset-tools\n",
        "    !pip install -r util/requirements.txt\n",
        "else:\n",
        "    !git clone https://github.com/dougrosman/pix2pixHD\n",
        "    %cd pix2pixHD\n",
        "    !mkdir generated_videos\n",
        "    !pip install dominate\n",
        "    !pip install -r util/requirements.txt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxg6p_9CPylP"
      },
      "source": [
        "## 4. Data Processing\n",
        "\n",
        "This notebook includes the following commands to help you create your data set:\n",
        "\n",
        "1. Create the required folders for organizing your training data\n",
        "1. Extract frames from a video file using FFMPEG\n",
        "1. Create Canny edge versions of your images for your input (train_A) images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-tEfNmWUlJR"
      },
      "source": [
        "### **Notes on preparing your dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tz3387OwYhJ2"
      },
      "source": [
        "1. **Identical image quantities:** The number of input images (train_A) should be identical to the number of output images (train_B). Otherwise, your training data will be mismatched, and won't train well.\n",
        "1. **Same order:** The images in your train_A folder should be in the same order as the images in your train_B folder. They are fed into pix2pixHD in alphatbetical/numerical order. Your images should automatically be in the same order, but keep this in mind just in case you notice mismatches in your results.\n",
        "1. **Consistent image dimensions** of all your input images should have the same dimensions, and all your output images should have the same dimensions.\n",
        "1. **Consistent input/output dimensions:** Technically, pix2pixHD can train datasets where the input dimensions are different from the output (like if you were training an image upscaler), but for most situations, your input and output dimensions should match.\n",
        "1. **Dataset size:** Depending on your goals, and the type of data you're working with, the amount of images you need for a \"successful\" model will vary. Some general tips: I would aim for **_500 image pairs minimum, but more is better. Shoot for the 2,000-5,000 image pair range)._** For example, if your dataset has 1,000 images, that means it has 2x 1,000 images -- 1,000 input images (train_A), and 1,000 output images (train_B).\n",
        "1. **Efficient dataset management:** Uploading and downloading thousands of images using Google Drive can be painfully slow. I recommend downloading and installing [Google Backup and Sync](https://www.google.com/drive/download/) (Google Drive's desktop application for automatic file syncing). If you set it up, I recommend only syncing the specific dataset folders in your Google Drive that you want to work with, otherwise you might end up downloading too much to your computer. Also, during the first step of the setup process, make sure to click 'Sign in with your browser.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQzZZsDwP9Wo"
      },
      "source": [
        "### 4a. Create necessary dataset folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxL2IHdBTQ6x"
      },
      "source": [
        "#### **Set your Dataset Name**\n",
        "\n",
        "The dataset_name variable you set here will be used throughout the rest of the notebook. Any time you work with a new dataset, change the name here. **_Any instance of $dataset_name you encounter will refer to whatever you set in this code cell._**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yUYJX2UJm0N"
      },
      "source": [
        "dataset_name = 'my_dataset' # change 'dataset_name' to whatever you want to call your dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgyGln8INiJR"
      },
      "source": [
        "#### **Create your dataset folders**\n",
        "Inside your datasets folder, you'll need a folder for each dataset you work with. The following command creates these folders:\n",
        "  1. **_train_A_**, for your input images. Place your input images inside that folder.\n",
        "  2. **_train_B_**, for your output images. Place your output images inside that folder.\n",
        "  3. **_test_A_**, for you test input images. We won't use this folder until we get the generate steps after training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c8mtNpKQGON"
      },
      "source": [
        "# Run this cell after setting your dataset_name above\n",
        "\n",
        "!mkdir ./datasets/$dataset_name\n",
        "!mkdir ./datasets/$dataset_name/train_A\n",
        "!mkdir ./datasets/$dataset_name/train_B\n",
        "!mkdir ./datasets/$dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptpbVFmHY5QS"
      },
      "source": [
        "### 4b. Upload your images\n",
        "\n",
        "If you prepared your dataset images outside this notebook, upload them to the correct folders. Otherwise, skip this step.\n",
        "\n",
        "Upload your input images (if you have them) to the train_A folder (e.g., your canny edges), and your output images to the train_B folder (e.g., the real images).\n",
        "\n",
        "I recommend doing this in a separate tab that is opened to your Google Drive folder. Uploading large amounts of files inside Colab doesn't work very well. Or, use Backup and Sync (details above in the 'Notes on preparing your dataset' section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxU5jLsCqMLT"
      },
      "source": [
        "### 4c. Extract frames from video â€“ create train_B (output) images\n",
        "If you plan to create a dataset by extracting images from a video file, follow these steps.\n",
        "First, upload the video file to the **dataset folder** that contains your train_A, train_B and test_A folders.\n",
        "\n",
        "Make sure the name of your video file is 'input.mp4'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UqqKDZIqMLU"
      },
      "source": [
        "# change scale to your desired resolution to resize your images. (1280:-1 scales\n",
        "  ## images to 1280 for the width, and the height is scaled to maintain the aspect ratio)\n",
        "  ## change the width to whatever makes sense for your images (I haven't tested\n",
        "  ## anything larger than 1280x720, but you may be able to go larger. If you experience\n",
        "  ## an out of memory error, it might be because your images are too large.)\n",
        "# change the fps (number of frames per second to extract);\n",
        "  ## higher fps = more images to extract, 6-12 is a good range. You likely don't need every\n",
        "  ## single frame from your video to make a good data set.\n",
        "\n",
        "!ffmpeg \\\n",
        " -i ./datasets/$dataset_name/input.mp4 \\\n",
        " -vf scale=1280:-1,fps=8 \\\n",
        " ./datasets/$dataset_name/train_B/output%5d.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF3xtN1SRrSC"
      },
      "source": [
        "### 4d. Apply Canny Edge Detection - create train_A (input) images\n",
        "This step uses [Canny Edge Detection](https://en.wikipedia.org/wiki/Canny_edge_detector) to find edges in your input images. The outlined images are rendered and stored in the train_A folder.\n",
        "\n",
        "**Whether you uploaded your train_B images, or got your train_B images by extracting them from a video, you should run this step if you're creating canny edge images.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGqScjsWR0UT"
      },
      "source": [
        "# change blur amount if there are too many lines in your resulting Canny Edge\n",
        "# images (odd numbers only; start with 5, then try 3 if 5 doesn't give you enough lines)\n",
        "\n",
        "# change max_size to be the max dimension of your input images (e.g., if your\n",
        "# input images are 1280x720, set max_size to '1280')\n",
        "\n",
        "!python util/dataset-tools.py \\\n",
        "--input_folder ./datasets/$dataset_name/train_B/ \\\n",
        "--output_folder ./datasets/$dataset_name/train_A/ \\\n",
        "--process_type canny \\\n",
        "--blur_type gaussian \\\n",
        "--blur_amount 3 \\\n",
        "--max_size 1024 \\\n",
        "--verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoaXeKHDzln6"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAYhoXtqSrij"
      },
      "source": [
        "### **Some notes on training:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn5UCjrdEc26"
      },
      "source": [
        "* **To stop your training manually**, click the stop button on the cell that's running your training.\n",
        "* **You should only train using a P100 or a V100** (step 1 in the notebook tells you which care you have).\n",
        "* **There's no set time for how much training your model needs to get the results you want**, but at least 60 epochs is ideal (more is likely better)\n",
        "* **Watch your checkpoints folder as you train.** You can track quality of your training by viewing the sample images that are automatically generated during training. These live in the checkpoints folder, in the folder for your current training. Inside of there, go into web-->images to see your sample images. If it looks like your training is getting __*worse*__, then stop your training.\n",
        "* **When you start your training, stick around for the first 10-15 minutes,** Google Colab sometimes checks to see if you're a robot around that time, so make sure you're there to confirm your humanity.\n",
        "* **Don't close this tab!** You can do other things on your computer, and browse other tabs, but just don't close the tab!\n",
        "* **Don't close your laptop!**\n",
        "* **Don't let your computer fall asleep.** Go into your system settings to make sure your computer won't fall asleep.\n",
        "* **On a free account, you'll get around ~7-10 hours of continuous training.**\n",
        "* **On a pro account, you'll get around ~18-24 hours of continuous training.**\n",
        "* **For free accounts, if you train for around ~40 hours or so in a single week, Google may \"shadowban\" you for a bit**, meaning you might not be able to connect to a GPU until after waiting a few hours (or sometimes an entire day). If you're running into these issues, I recommend Google Colab Pro (it's only $9.99 for the month, and totally worth it).\n",
        "* **You can't do anything else in this notebook while training.** If you want to generate images while training, I recommend opening up a second Colab notebook in another Google account. Note, Google might be on to you if it finds you're using like, 5 Colab notebooks simultaneously. Proceed with this at your own risk. Just make sure you don't mount the same Drive folder in step 2 from multiple Colab notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhsyaD2T0Kdi"
      },
      "source": [
        "### 5a. Setting your training variables (required for both training from scratch AND resuming training)\n",
        "\n",
        "Set the following variables, whether you're training from scratch or resuming training. After change the variables, click the play button in this cell to save your values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unqheWJPwd4A"
      },
      "source": [
        "##### REQUIRED: edit these each time you train a new model from scratch!\n",
        "name = 'training_name'    # can be whatever you want; name this based on your dataset (e.g. edges2cats)\n",
        "loadSize = 1280     # The desired width of your outputs (note: images will be cropped to this) Default=1024 \n",
        "fineSize = 720      # The desired height of your outputs\n",
        "                    ## I haven't trained a model with images larger than 1280x720, though it may be possible!\n",
        "which_epoch = 'latest' # The epoch you wish to resume training from. Keep this set to 'latest' if you want to\n",
        "                        ## pick up from where you left off. Otherwise, put the number of the .pth file you want\n",
        "                        ## to resume from (e.g. 10, 20, 30, etc.)\n",
        "\n",
        "##### OPTIONAL: change these if needed\n",
        "resize_or_crop = 'scale_width'  # keeping this unchanged will automatically resize\n",
        "                                  ## your images to the loadSize and fineSize, then crop to\n",
        "                                  ## those dimensions. Set to 'none' if your images are\n",
        "                                  ## already the correct dimensions\n",
        "\n",
        "display_freq = 200    # frequency of showing training results on screen\n",
        "print_freq = 100      # frequency of showing training results on console\n",
        "save_latest_freq = 1000     # frequency of saving the latest results\n",
        "                              ##(lower = more frequent saving, 1000 ~ saves every 10 minutes)\n",
        "save_epoch_freq = 10    # frequency of saving checkpoints at the end of epochs\n",
        "                        # (1 epoch is completed after going through every image in your data set 1 time)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfzVC9CMg_9k"
      },
      "source": [
        "### 5b. Running the training command"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtamNKBNcm4E"
      },
      "source": [
        "#### **Option 1: Training a new model from scratch**\n",
        "\n",
        "Unlike StyleGAN, where use transfer learning by resuming training from a pretrained model like FFHQ, with pix2pixHD, it's much more common to train a model from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSAXRvJecuyr"
      },
      "source": [
        "# ONLY RUN THIS IF YOU ARE STARTING A NEW TRAINING\n",
        "!python train.py --name=$name --dataroot=./datasets/$dataset_name --checkpoints_dir checkpoints --no_instance --label_nc 0 --resize_or_crop=$resize_or_crop --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RTJPr0d1wid"
      },
      "source": [
        "#### **Option 2: Resuming a training**\n",
        "\n",
        "Run this command if you are resuming training. You should still set your variables above before running this command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_rDOKsb1wif"
      },
      "source": [
        "# ONLY RUN THIS IF YOU ARE RESUMING A TRAINING\n",
        "!python train.py --name=$name --dataroot=./datasets/$dataset_name --checkpoints_dir checkpoints --no_instance --label_nc 0 --resize_or_crop=$resize_or_crop --continue_train --which_epoch=$which_epoch --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSrr8dQ_n8T"
      },
      "source": [
        "## 6. Generating Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbhWt6X1ddv-"
      },
      "source": [
        "In order to generate images with pix2pixHD, you need to feed the model with \"test\" images. Your test images should look like your input (train_A) images. For example, if your train_A images used Canny Edge images, then your test images should also be Canny Edge images.\n",
        "\n",
        "pix2pixHD takes the images from your test_A folder and feeds them into your trained model. Any time you want to test new input images with your model, you'll need to replace the images in the test_A folder with your new images.\n",
        "\n",
        "Inevitably, pix2pixHD will have you working with a large amount of images spread across a number of different folders, and your file organization can get out of hand if you don't plan ahead a bit.\n",
        "\n",
        "The following code cells provide tools to prepare your test images. None are required, so read the description before each cell to see if that's something you want to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RErlE8BMjKut"
      },
      "source": [
        "### 6a. Preparing your test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJDzGIwTStcM"
      },
      "source": [
        "#### **Set your experiment name**\n",
        "\n",
        "The experiment_name variable you set here will be used throughout the rest of the notebook. Any time you work with a new experiment, change the name here. **_Any instance of $experiment_name you encounter will refer to whatever you set in this code cell._**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZSuX--cPobs"
      },
      "source": [
        "experiment_name = 'my_experiment_name' # change 'my_experiment_name' to whatever you want to call your experiment"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-QOSV5bhdsh"
      },
      "source": [
        "#### **Set your Dataset Name**\n",
        "\n",
        "(Note: if you're doing this step in the same session as your training, your dataset_name will have already been set. Feel free to set it again anytime you're generating images using a different dataset/trained model).\n",
        "\n",
        "The dataset_name variable you set here will be used throughout the rest of the notebook. Any time you work with a new dataset, change the name here. **_Any instance of $dataset_name you encounter will refer to whatever you set in this code cell._**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpVA791whdsi"
      },
      "source": [
        "dataset_name = 'my_dataset' # change 'dataset_name' to whatever you want to call your dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32q351TCYGOa"
      },
      "source": [
        "#### **Option 1:** Generating images from your original training data (the images from your train_A folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FYWs8Wdd2r4"
      },
      "source": [
        "1. This cell removes any images from your test_A folder (if there are any), and... \n",
        "2. Copies all the images from your train_A folder to your test_A folder.\n",
        "Testing your trained model with the original data set can be useful to see how accurately the model can recreate the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbohBwO3KHFm"
      },
      "source": [
        "# remove any images currently in test_A\n",
        "!rm -v ./datasets/$dataset_name/test_A/*.png\n",
        "\n",
        "# copy images from train_A to test_A\n",
        "!cp -v ./datasets/$dataset_name/train_A/*.png ./datasets/$dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "big1f7SvaB7p"
      },
      "source": [
        "#### **Option 2: Testing with Canny Edge images from a new input source.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or94rxGsd63A"
      },
      "source": [
        "This is where it starts to get important to stay organized. This command creates a folder inside of \"input_test_images\" (which lives in your datasets folder). **Do this for each new experiment you create.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1MbcuHTcjde"
      },
      "source": [
        "# create a folder + relevant subfolders for your new experiment\n",
        "!mkdir ./datasets/input_test_images/$experiment_name\n",
        "!mkdir ./datasets/input_test_images/$experiment_name/extracted_frames\n",
        "!mkdir ./datasets/input_test_images/$experiment_name/canny_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMh4tpXnHAmZ"
      },
      "source": [
        "#### **Upload your source video**\n",
        "After running the above cell, upload the video to the [experiment_name] folder you created above.\n",
        "\n",
        "Make sure the video file is called **input.mp4**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCSsYCKXIQZ1"
      },
      "source": [
        "#### **Extract frames from source video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1FhLxYm9Rbw"
      },
      "source": [
        "# change scale to your desired resolution to resize your images. (1280:-1 scales\n",
        "  ## images to 1280 for the width; the height is scaled to maintain the aspect ratio)\n",
        "  ## change the width to whatever makes sense for your images (I haven't tested\n",
        "  ## anything larger than 1280, but you might be able to go up to 1440 or 1600)\n",
        "# change the fps (number of frames per second to extract);\n",
        "  ## this time, you probably want all the frames from the video, so set\n",
        "  ## the fps to the fps of your input video.\n",
        "# change output%5d.png to include a reference to your experiment_name\n",
        "\n",
        "!ffmpeg \\\n",
        " -i ./datasets/input_test_images/$experiment_name/input.mp4 \\\n",
        " -vf scale=1280:-1,fps=30 \\\n",
        " ./datasets/input_test_images/$experiment_name/extracted_frames/output%5d.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFDYgh1qIFFz"
      },
      "source": [
        "#### **Apply Canny Edge Detection - create test_A images**\n",
        "If your images are already prepared and don't need to be converted to Canny edges, you don't need to do this step. This step uses [Canny Edge Detection](https://en.wikipedia.org/wiki/Canny_edge_detector) to find edges in your input images. The outlined images are rendered and stored in the canny_edges folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naunWl-qAO1v"
      },
      "source": [
        "# change blur amount if there are too many lines in your resulting Canny Edge\n",
        "# images (odd numbers only; start with 5, then try 3 if 5 doesn't give you enough lines)\n",
        "\n",
        "# change max_size to be the max dimension of your input images (e.g., if your\n",
        "# input images are 1280x720, set max_size to '1280')\n",
        "\n",
        "!python util/dataset-tools.py \\\n",
        "--input_folder ./datasets/input_test_images/$experiment_name/extracted_frames/ \\\n",
        "--output_folder ./datasets/input_test_images/$experiment_name/canny_edges \\\n",
        "--process_type canny \\\n",
        "--blur_type gaussian \\\n",
        "--blur_amount 3 \\\n",
        "--max_size 1280 \\\n",
        "--verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C31h725KWLx"
      },
      "source": [
        "#### **Put your test images in the correct folders**\n",
        "Run this cell to remove any images currently in test_A, then copy your new Canny Edge Images to the test_A folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dNWXdhc6d4h"
      },
      "source": [
        "# remove any images currently in test_A (change dataset_name to your dataset_name)\n",
        "!rm -v ./datasets/$dataset_name/test_A/*.png\n",
        "\n",
        "# copy your canny edge images into test_A (change experiment_name and dataset_name)\n",
        "!cp -v ./datasets/input_test_images/$experiment_name/canny_edges/*.png ./datasets/$dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTkwfWoOAUbS"
      },
      "source": [
        "### 6b. Running the generate command\n",
        "\n",
        "Change your variables as need below, then run the cell to save the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyljQEtxFjtd"
      },
      "source": [
        "##### REQUIRED: edit these each time each you generate images\n",
        "loadSize = 1280 # set this to the width of your input images\n",
        "fineSize = 720  # set this to the height of your input images\n",
        "how_many = 400  # The number of images you wish to generate. Make sure this is\n",
        "                ## greater than or equal to the number of images you're trying to generate\n",
        "\n",
        "##### OPTIONAL: change these if needed\n",
        "which_epoch = 'latest' # The epoch you wish to generate images from (e.g. '20') (Defult: latest. I recommend this)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V73BNBbr_0R9"
      },
      "source": [
        "# Run this cell to generate your images. This may take a few minutes.\n",
        "!python test.py --name=$dataset_name --dataroot=./datasets/$dataset_name --checkpoints_dir checkpoints --results_dir=./results/$experiment_name --which_epoch=$which_epoch --how_many=$how_many --no_instance --label_nc 0 --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AITt0XwQr5yX"
      },
      "source": [
        "## 7. Creating videos from your generated images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIMtiI26BKVk"
      },
      "source": [
        "### 7a. Create video of your test input images\n",
        "_Thread your test_A images together into a video. If your input images used Canny Edge, then this will be a video of your Canny Edge inputs._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLTMmMolJa4Y"
      },
      "source": [
        "1. **-i**: the input images _(the filepath to your synthesized images)_\n",
        "1. **-r**: the framerate _(any value between 1-60)_\n",
        "1. **-crf**: the compression quality of the output video _(lower is better, 17-25 is a good range)_\n",
        "1. **_the output filename_**: the last argument; make sure to set this each time you create a new video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkEOfx5sJ6z"
      },
      "source": [
        "# Change 'input_images_sequence.mp4' to something more descriptive (e.g. edges2cats_input_edges.mp4).\n",
        "# MAKE SURE TO CHANGE THIS EACH TIME TO AVOID OVERWRITING OTHER GENERATED VIDEOS\n",
        "!ffmpeg \\\n",
        "   -pattern_type glob \\\n",
        "   -i \"./results/$experiment_name/$dataset_name/test_latest/images/*_input_label.png\" \\\n",
        "   -r 30 \\\n",
        "   -vcodec libx264 \\\n",
        "   -crf 23 \\\n",
        "   -pix_fmt yuv420p \\\n",
        "   ./generated_videos/input_images_sequence.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X7A6HUsBXx6"
      },
      "source": [
        "### 7b. Create video of your synthesized images\n",
        "_Thread your synthesized images together into a video._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoDrHlPaJOpC"
      },
      "source": [
        "1. **-i**: the input images _(the filepath to your synthesized images)_\n",
        "1. **-r**: the framerate _(any value between 1-60)_\n",
        "1. **-crf**: the compression quality of the output video _(lower is better, 17-25 is a good range)_\n",
        "1. **_the output filename_**: the last argument; make sure to set this each time you create a new video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwZDYXvSBdS6"
      },
      "source": [
        "# Change 'synthesized_output' to something more related to this experiment (e.g. edges2cats_synthesized.mp4).\n",
        "# MAKE SURE TO CHANGE THIS EACH TIME TO AVOID OVERWRITING OTHER GENERATED VIDEOS\n",
        "!ffmpeg \\\n",
        "   -pattern_type glob \\\n",
        "   -i \"./results/$experiment_name/$dataset_name/test_latest/images/*_synthesized_image.png\" \\\n",
        "   -r 30 \\\n",
        "   -vcodec libx264 \\\n",
        "   -crf 23 \\\n",
        "   -pix_fmt yuv420p \\\n",
        "   ./generated_videos/synthesized_output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
