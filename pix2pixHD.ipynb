{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pix2pixHD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qAYhoXtqSrij"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVO-LxDxs1YR"
      },
      "source": [
        "# Pix2PixHD\n",
        "\n",
        "This notebook was created by Doug Rosman, and uses code from [Doug's forked pix2pixHD repository](https://github.com/dougrosman/pix2pixHD). For a video tutorial showing how to use this notebook, visit this link here: [https://dougrosman.github.io/cvml-sp21/resources/pix2pixHD/](https://dougrosman.github.io/cvml-sp21/resources/pix2pixHD/)\n",
        "\n",
        "The notes in this notebook try to be as comprehensive as possible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewD4YcUPt3Qf"
      },
      "source": [
        "## 1. Connect to a GPU Instance (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4yKFd4zJ6C"
      },
      "source": [
        "**Executing this cell will connect you to a GPU, and your 8-10 hours of free GPU time will begin.**\n",
        "\n",
        "This will show you what GPU you've been randomly given for this instance. With a Google Colab Pro account ($9.99/mo, really worth it!), you're almost always guaranteed a **P100**, with a chance at getting a **V100**.\n",
        "* **V100:** Best, (not available for free accounts)\n",
        "* **P100:** Great\n",
        "* **T4:** (untested) this might *not* work for training.\n",
        "* **K80:** (untested) this might work, but it will likely be very slow.\n",
        "\n",
        "If you get a T4 or K80, I encourage you to terminate your session, wait 5-10 minutes, then try connecting to a GPU again. To terminate your session, at the top of your screen go to **Runtime** --> **Manage Sessions** --> **Terminate**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KisNe7y5as8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c7fb67-d6c1-419d-9c39-f0a9abee65e2"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-526bbc98-400a-52d6-db5a-76574dc2be5e)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD-3fgfwNd8"
      },
      "source": [
        "## 2. Mount your Google Drive (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhemEUvrzTif"
      },
      "source": [
        "**Executing this cell will prompt you to mount your Google Drive.**\n",
        "\n",
        "After executing, a link will show up. Click the link and follow the directions. Select the Google Drive you wish to use (use your SAIC account since it has unlimited storage). Copy and paste the authorization key into the box below, and press 'Enter' or 'Return' on your keyboard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Id6wSjbH5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688a1b6d-36e8-4765-efb0-92f5cd74a022"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DvGIfacxJL_"
      },
      "source": [
        "## 3. Install pix2pixHD repository OR change directory into repo (required)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdOJwnvTzbn0"
      },
      "source": [
        "**Executing this cell will either install the pix2pixHD repo into your Google Drive, or move you into the pix2pixHD repo if it already exists. This cell also installs a python dependency called _dominate_.**\n",
        "\n",
        "**Case 1: Installing the repo**\n",
        "If this is your first time using this notebook (or if you deleted a previously installed version of the pix2pixHD repo in you Google Drive), this cell will clone Doug Rosman's forked pix2pixHD repo into your Google Drive into a folder called 'colab-pix2pixHD'. After cloning, it will move you into the pix2pixHD folder.\n",
        "\n",
        "**Case 2: Moving into the repo**\n",
        "If this repo already exists in your Google drive, this cell will move you into the pix2pixHD folder so that you can execute the other cells in this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQpxYVIbLja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "992b895a-6423-4bb4-d0ea-cfe6cc358741"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/colab-pix2pixHD\"):\n",
        "    %cd \"/content/drive/MyDrive/colab-pix2pixHD/pix2pixHD\"\n",
        "    !pip install dominate\n",
        "    !pip install -r util/requirements.txt\n",
        "elif os.path.isdir(\"/content/drive/\"):\n",
        "    #install script\n",
        "    %cd \"/content/drive/MyDrive/\"\n",
        "    !mkdir colab-pix2pixHD\n",
        "    %cd colab-pix2pixHD\n",
        "    !git clone https://github.com/dougrosman/pix2pixHD\n",
        "    %cd pix2pixHD\n",
        "    !mkdir generated_videos\n",
        "    !pip install dominate\n",
        "    #install python requirements for Derrick Schultz' dataset-tools.py\n",
        "    #more info: https://github.com/dvschultz/dataset-tools\n",
        "    !pip install -r util/requirements.txt\n",
        "else:\n",
        "    !git clone https://github.com/dougrosman/pix2pixHD\n",
        "    %cd pix2pixHD\n",
        "    !mkdir generated_videos\n",
        "    !pip install dominate\n",
        "    !pip install -r util/requirements.txt\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-pix2pixHD/pix2pixHD\n",
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r util/requirements.txt (line 1)) (1.19.5)\n",
            "Collecting imutils==0.5.2\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/0c/659c2bdae8e8ca5ef810b9da02db28feaa29ea448ff36b65a1664ff28142/imutils-0.5.2.tar.gz\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from -r util/requirements.txt (line 3)) (4.1.2.30)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r util/requirements.txt (line 4)) (1.4.1)\n",
            "Collecting mac-tag\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/a4/3c1c2efb7cf795bcf382b66da7b8dc3ae0e20848a2be43499ce7ea2e9bc3/mac-tag-2020.12.3.tar.gz\n",
            "Collecting psd-tools3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/1b/88e605453a5d2b2168140bb520c4aa6361d7cce742b5e6ae8a8a14638959/psd-tools3-1.8.2.tar.gz (167kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 5.8MB/s \n",
            "\u001b[?25hCollecting lpips\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/de/774d9cdb601bb938b6a501f1aeaa64288a763ebbafbeef227a3da86150d9/lpips-0.1.3-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n",
            "\u001b[?25hCollecting runcmd\n",
            "  Downloading https://files.pythonhosted.org/packages/41/b7/08c18bc2944c0443aa77672e5610e861c6946f93f247bef0aa8d7737b248/runcmd-2020.12.3.tar.gz\n",
            "Collecting values\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/18/952219903bde3175113927866c19b536cfcea3259cd4e3fdacb8604723f6/values-2020.12.3.tar.gz\n",
            "Requirement already satisfied: docopt>=0.5 in /usr/local/lib/python3.7/dist-packages (from psd-tools3->-r util/requirements.txt (line 6)) (0.6.2)\n",
            "Collecting packbits\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/23/78a967c9b9961258da2bf0d0a63bf12293ccddf96ec77361ee7b44f543f1/packbits-0.6.tar.gz\n",
            "Collecting exifread\n",
            "  Downloading https://files.pythonhosted.org/packages/91/c6/177a40fefa6e9ed1a10f0f98863a7137b0a89c4eae5609b9737926dba85f/ExifRead-2.3.2-py3-none-any.whl\n",
            "Collecting PyBundle\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/62/ff42854a129c8e301157d5cc294b6d03fbd3e6755c8c19755f81298cf5d6/PyBundle-1.0.6.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from runcmd->mac-tag->-r util/requirements.txt (line 5)) (5.4.8)\n",
            "Building wheels for collected packages: imutils, mac-tag, psd-tools3, runcmd, values, packbits, PyBundle\n",
            "  Building wheel for imutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imutils: filename=imutils-0.5.2-cp37-none-any.whl size=24417 sha256=7bf847664880fb237710952059f02ae6f3bc974ab316cf1e4bc87c7d542f2823\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/40/59/139d450e68847ef2f27d876d527b13389dac23df0f66526b5d\n",
            "  Building wheel for mac-tag (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mac-tag: filename=mac_tag-2020.12.3-cp37-none-any.whl size=1945 sha256=cdf4e86c7e069129bae0f5392a2212d89e3c0e011a2aad26d86b95914b781a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/ee/c1/091428c85c2a519cce6ccb30281f0d6130a9e17424a322ccc7\n",
            "  Building wheel for psd-tools3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for psd-tools3: filename=psd_tools3-1.8.2-cp37-none-any.whl size=81619 sha256=3da6f8553049be19fe93a771d2e8b5b9a0ebcd1af40733d8150794e7f5af1012\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/c2/8b/959f19ef56e627c892e5bc93bdf2fbc34d620431b3a45e7dd8\n",
            "  Building wheel for runcmd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for runcmd: filename=runcmd-2020.12.3-cp37-none-any.whl size=2390 sha256=9a7479d6f5ec888774278fff5a2b228f1625a527952ea718b2ae5be884af2b30\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/da/4a/919941336da2cf9602c5146115b86073a5dc6d6e4a4524b400\n",
            "  Building wheel for values (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for values: filename=values-2020.12.3-cp37-none-any.whl size=1403 sha256=bbd973c73b4d70b4774c070988cae2f7ff48119c06d3bf8b492444333ba4960e\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/ae/4f/3c3954bcfd34d33a760db86564e53eed2817cf4c1540ec35b5\n",
            "  Building wheel for packbits (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for packbits: filename=packbits-0.6-cp37-none-any.whl size=2665 sha256=f2bf2afc35108ccc73a3f8de5115543e97e6f8befe5d5d2c45f6dfa72638ac17\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/08/ca/c39b0b8978dedaa67e8b068f608f6455e7460b2b5e800d03fa\n",
            "  Building wheel for PyBundle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyBundle: filename=PyBundle-1.0.6-cp37-none-any.whl size=2146 sha256=2661b30eb1b0782fe7c93d410ed850fdb0d7dec54061c2711b8382653dda3c38\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/be/1b/13f820b66b88c137b3b367b2ef346d1be97a0fa91a95926a24\n",
            "Successfully built imutils mac-tag psd-tools3 runcmd values packbits PyBundle\n",
            "Installing collected packages: imutils, runcmd, values, mac-tag, packbits, exifread, PyBundle, psd-tools3, lpips\n",
            "  Found existing installation: imutils 0.5.4\n",
            "    Uninstalling imutils-0.5.4:\n",
            "      Successfully uninstalled imutils-0.5.4\n",
            "Successfully installed PyBundle-1.0.6 exifread-2.3.2 imutils-0.5.2 lpips-0.1.3 mac-tag-2020.12.3 packbits-0.6 psd-tools3-1.8.2 runcmd-2020.12.3 values-2020.12.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxg6p_9CPylP"
      },
      "source": [
        "## 4. Data Processing\n",
        "\n",
        "This notebook includes the following commands to help you create your data set:\n",
        "\n",
        "1. Create the required folders for organizing your training data\n",
        "1. Extract frames from a video file using FFMPEG\n",
        "1. Create Canny edge versions of your images for your input (train_A) images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQzZZsDwP9Wo"
      },
      "source": [
        "### 4a. Create necessary folders and upload dataset files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgyGln8INiJR"
      },
      "source": [
        "1. Inside your datasets folder, create a folder and name it based on the content of your dataset. Create the following two folders inside that folder (**note: your folder names must match these exactly**):\n",
        "  1. **_train_A_**, for your input images. Place your input images inside that folder.\n",
        "  2. **_train_B_**, for your output images. Place your output images inside that folder.\n",
        "\n",
        "The following command creates the folders for you. Just change 'your_dataset_name' to something indicative of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c8mtNpKQGON"
      },
      "source": [
        "# create a folder for your dataset (change your_dataset_name to whatever your dataset is)\n",
        "!mkdir ./datasets/dataset_name\n",
        "\n",
        "# creates three folders inside your datasets folder, one for your input (train_A),\n",
        "# one for your output (train_B), and one for your test images (test_A)\n",
        "!mkdir ./datasets/dataset_name/train_A\n",
        "!mkdir ./datasets/dataset_name/train_B\n",
        "!mkdir ./datasets/dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWXBZEesM1Fx"
      },
      "source": [
        "Before proceeding to the next step, upload the video that you will be using to extract images to your dataset folder.\n",
        "\n",
        "If your images are already prepared, upload your input images to the train_A folder, and your output images to the train_B folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxU5jLsCqMLT"
      },
      "source": [
        "### 4b. Extract frames from video – create train_B (output) images\n",
        "If your images are already prepared and don't need to be extracted from a video file, you don't need to do this step. Your extracted frames will end up in the train_B folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UqqKDZIqMLU"
      },
      "source": [
        "# change dataset_name to the dataset_name you created above\n",
        "# change input.mp4 file to the name of your video file\n",
        "# change scale to your desired resolution to resize your images. (1280:-1 scales\n",
        "  ## images to 1280 for the width; the height is scaled to maintain the aspect ratio)\n",
        "  ## change the width to whatever makes sense for your images (I haven't tested\n",
        "  ## anything larger than 1280, but you might be able to go up to 1440 or 1600)\n",
        "# change the fps (number of frames per second to extract);\n",
        "  ## higher fps = more images to extract, 4-12 is a good range\n",
        "\n",
        "!ffmpeg \\\n",
        " -i ./datasets/dataset_name/input.mp4 \\\n",
        " -vf scale=1280:-1,fps=8 \\\n",
        " ./datasets/dataset_name/train_B/output%5d.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF3xtN1SRrSC"
      },
      "source": [
        "### 4c. Apply Canny Edge Detection - create train_A (input) images\n",
        "If your images are already prepared and don't need to be converted to Canny edges, you don't need to do this step. This step uses [Canny Edge Detection](https://en.wikipedia.org/wiki/Canny_edge_detector) to find edges in your input images. The outlined images are rendered and stored in the train_A folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGqScjsWR0UT"
      },
      "source": [
        "# change --input_folder to the path to your train_B folder\n",
        "# change --output_folder to the path to your train_A folder\n",
        "\n",
        "# change blur amount if there are too many lines in your resulting Canny Edge\n",
        "# images (odd numbers only, 1-5 is a good range)\n",
        "\n",
        "# change max_size to be the max dimension of your input images (e.g., if your\n",
        "# input images are 1280x720, set max_size to '1280')\n",
        "\n",
        "!python util/dataset-tools.py \\\n",
        "--input_folder ./datasets/canny_tests/train_B/ \\\n",
        "--output_folder ./datasets/canny_tests/c100_250/ \\\n",
        "--process_type canny \\\n",
        "--blur_type gaussian \\\n",
        "--blur_amount 3 \\\n",
        "--max_size 1024 \\\n",
        "--verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoaXeKHDzln6"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAYhoXtqSrij"
      },
      "source": [
        "### **Some notes on training:** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn5UCjrdEc26"
      },
      "source": [
        "* **To stop your training manually**, click the stop button on the cell that's running your training.\n",
        "* **You should only train using a P100 or a V100** (step 1 in the notebook tells you which care you have).\n",
        "* **There's no set time for how much training your model needs to get the results you want**, but at least 60 epochs is ideal (more is likely better)\n",
        "* **Watch your results folder as you train.** If it looks like your training is getting __*worse*__, then stop your training.\n",
        "* **When you start your training, stick around for the first 10-15 minutes,** Google Colab checks to see if you're a robot around that time, so make sure you're there to confirm your humanity.\n",
        "* **Don't close this tab!** You can do other things on your computer, and browse other tabs, but just don't close the tab!\n",
        "* **Don't close your laptop!**\n",
        "* **Don't let your computer fall asleep.** Go into your system settings to make sure your computer won't fall asleep.\n",
        "* **On a free account, you'll get around ~7-10 hours of continuous training.**\n",
        "* **On a pro account, you'll get around ~18-24 hours of continuous training.**\n",
        "* **For free accounts, if you train for around ~40 hours or so in a single week, Google may \"shadowban\" you for a bit**, meaning you might not be able to connect to a GPU until after waiting a few hours (or sometimes an entire day). If you're running into these issues, I recommend Google Colab Pro (it's only $9.99 for the month, and totally worth it).\n",
        "* **You can't do anything else in this notebook while training.** If you want to generate images while training, I recommend opening up a second Colab notebook in another Google account. Note, Google might be on to you if it finds you're using like, 5 Colab notebooks simultaneously. Proceed with this at your own risk. Just make sure you don't mount the same Drive folder in step 2 from multiple Colab notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhsyaD2T0Kdi"
      },
      "source": [
        "### 5a. Training a new model from scratch (required for both training from scratch AND resuming training)\n",
        "\n",
        "Set the following variables, whether you're training from scratch or resuming training. After change the variables, click the play button in this cell to save your values. If you're resuming a training, set your variables, then skip to step 5b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unqheWJPwd4A"
      },
      "source": [
        "##### REQUIRED: edit these each time you train a new model from scratch!\n",
        "name = 'training_name'    # can be whatever you want; name this based on your dataset (e.g. wave_pool)\n",
        "dataroot = 'datasets/dataset_name'  # must match the name of your dataset folder\n",
        "loadSize = 1280     # The desired width of your outputs (note: images will be cropped to this) Default=1024 \n",
        "fineSize = 720      # The desired height of your outputs\n",
        "which_epoch = 'latest' # The epoch you wish to resume training from. Keep this set to 'latest' if you want to\n",
        "                        ## pick up from where you left off. Otherwise, put the number of the .pth file you want\n",
        "                        ## to resume from (e.g. 10, 20, 30, etc.)\n",
        "\n",
        "##### OPTIONAL: change these if needed\n",
        "resize_or_crop = 'scale_width'  # keeping this unchanged will automatically resize\n",
        "                                  ## your images to the loadSize and fineSize, then crop to\n",
        "                                  ## those dimensions. Set to 'none' if your images are\n",
        "                                  ## already the correct dimensions\n",
        "\n",
        "display_freq = 200    # frequency of showing training results on screen\n",
        "print_freq = 100      # frequency of showing training results on console\n",
        "save_latest_freq = 1000     # frequency of saving the latest results\n",
        "                              ##(lower = more frequent saving, 1000 ~ saves every 10 minutes)\n",
        "save_epoch_freq = 10    # frequency of saving checkpoints at the end of epochs\n",
        "                        # (1 epoch is completed after going through every image in your data set 1 time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSAXRvJecuyr"
      },
      "source": [
        "# ONLY RUN THIS IF YOU ARE STARTING A NEW TRAINING\n",
        "!python train.py --name=$name --dataroot $dataroot --checkpoints_dir checkpoints --no_instance --label_nc 0 --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RTJPr0d1wid"
      },
      "source": [
        "### 5b. Resuming your training (required if resuming training from a partially-trained model)\n",
        "\n",
        "Run this command if you are resuming training. You should still set your variables above before running this command."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_rDOKsb1wif"
      },
      "source": [
        "# ONLY RUN THIS IF YOU ARE RESUMING A TRAINING\n",
        "!python train.py --name=$name --dataroot=$dataroot --checkpoints_dir checkpoints --no_instance --label_nc 0 --continue_train --which_epoch=$which_epoch --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCSrr8dQ_n8T"
      },
      "source": [
        "## 6. Generating Images\n",
        "In order to generate images with pix2pixHD, you need to feed the model with \"test\" images. Your test images should look like your input (train_A) images. For example, if your train_A images used Canny Edge images, then your test images should also be Canny Edge images.\n",
        "\n",
        "**pix2pixHD takes the images from your test_A folder and feeds them into your trained model. Any time you want to test new input images with your model, you'll need to replace the images in the test_A folder with your new images.** \n",
        "\n",
        "Inevitably, pix2pixHD will have you working with a large amount of images spread across a number of different folders, and your file organization can get out of hand if you don't plan ahead a bit.\n",
        "\n",
        "The following code cells provide tools to prepare your test images. None are **required**, so read the description before each cell to see if that's something you want to do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RErlE8BMjKut"
      },
      "source": [
        "### 6a. Preparing your test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32q351TCYGOa"
      },
      "source": [
        "#### **Option 1:** Generating images from your original training data (the images from your train_A folder)\n",
        "1. This cell removes any images from your test_A folder (if there are any), and \n",
        "2. Copies all the images from your train_A folder to your test_A folder.\n",
        "Testing your trained model with the original data set can be useful to see how accurately the model can recreate the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbohBwO3KHFm"
      },
      "source": [
        "# remove any images currently in test_A\n",
        "!rm -v ./datasets/dataset_name/test_A/*.png\n",
        "\n",
        "# copy images from train_A to test_A\n",
        "!cp -v ./datasets/dataset_name/train_A/*.png ./datasets/dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "big1f7SvaB7p"
      },
      "source": [
        "#### **Option 2: Testing with Canny Edge images from a new input source.**\n",
        "This is where it starts to get important to stay organized. This command creates a folder inside of \"input_test_images\" (which lives in your datasets folder). **Do this for each new set of test images you create.**\n",
        "\n",
        "This notebook refers to new sets of test images as \"experiments\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1MbcuHTcjde"
      },
      "source": [
        "# create a folder + relevant subfolders for your new experiment\n",
        "!mkdir ./datasets/input_test_images/experiment_name\n",
        "!mkdir ./datasets/input_test_images/experiment_name/extracted_frames\n",
        "!mkdir ./datasets/input_test_images/experiment_name/canny_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMh4tpXnHAmZ"
      },
      "source": [
        "#### **Upload your source video**\n",
        "After running the above cell, upload the video to the [experiment_name] folder you created above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCSsYCKXIQZ1"
      },
      "source": [
        "#### **Extract frames from source video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1FhLxYm9Rbw"
      },
      "source": [
        "# change experiment_name to the experiment_name you created above\n",
        "# change input.mp4 file to the name of your video file\n",
        "# change scale to your desired resolution to resize your images. (1280:-1 scales\n",
        "  ## images to 1280 for the width; the height is scaled to maintain the aspect ratio)\n",
        "  ## change the width to whatever makes sense for your images (I haven't tested\n",
        "  ## anything larger than 1280, but you might be able to go up to 1440 or 1600)\n",
        "# change the fps (number of frames per second to extract);\n",
        "  ## this time, you probably want all the frames from the video, so set\n",
        "  ## the fps to the fps of your input video.\n",
        "# change output%5d.png to include a reference to your experiment_name\n",
        "\n",
        "!ffmpeg \\\n",
        " -i ./datasets/input_test_images/experiment_name/input.mp4 \\\n",
        " -vf scale=1280:-1,fps=30 \\\n",
        " ./datasets/input_test_images/experiment_name/extracted_frames/output%5d.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFDYgh1qIFFz"
      },
      "source": [
        "#### **Apply Canny Edge Detection - create test_A images**\n",
        "If your images are already prepared and don't need to be converted to Canny edges, you don't need to do this step. This step uses [Canny Edge Detection](https://en.wikipedia.org/wiki/Canny_edge_detector) to find edges in your input images. The outlined images are rendered and stored in the canny_edges folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naunWl-qAO1v"
      },
      "source": [
        "# change --input_folder (change experiment_name)\n",
        "# change --output_folder (change experiment_name)\n",
        "\n",
        "# change blur amount if there are too many lines in your resulting Canny Edge\n",
        "# images (odd numbers only, 1-5 is a good range)\n",
        "\n",
        "# change max_size to be the max dimension of your input images (e.g., if your\n",
        "# input images are 1280, set max_size to '1280')\n",
        "\n",
        "!python util/dataset-tools.py \\\n",
        "--input_folder ./datasets/input_test_images/experiment_name/extracted_frames/ \\\n",
        "--output_folder ./datasets/input_test_images/experiment_name/canny_edges \\\n",
        "--process_type canny \\\n",
        "--blur_type gaussian \\\n",
        "--blur_amount 3 \\\n",
        "--max_size 1280 \\\n",
        "--verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C31h725KWLx"
      },
      "source": [
        "#### **Put your test images in the correct folders**\n",
        "Run this cell to remove any images currently in test_A, then copy your new Canny Edge Images to the test_A folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dNWXdhc6d4h"
      },
      "source": [
        "# remove any images currently in test_A (change dataset_name to your dataset_name)\n",
        "!rm -v ./datasets/dataset_name/test_A/*.png\n",
        "\n",
        "# copy your canny edge images into test_A (change experiment_name and dataset_name)\n",
        "!cp -v ./datasets/input_test_images/experiment_name/canny_edges/*.png ./datasets/dataset_name/test_A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTkwfWoOAUbS"
      },
      "source": [
        "### 6b. Running the generate command\n",
        "\n",
        "Change your variables as need below, then run the cell to save the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyljQEtxFjtd"
      },
      "source": [
        "##### REQUIRED: edit these each time each you generate images\n",
        "\n",
        "name = 'wave_pool'        # change dataset_name; must match the name you set when you trained your model\n",
        "dataroot = 'datasets/wave_pool'  # change dataset_name; must match the name of your dataset folder\n",
        "results_dir = './results/how_many_test' # replace experiment_name with something descriptive of the image sequence you're generating\n",
        "loadSize = 1280 # set this to the width of your input images\n",
        "fineSize = 720 # set this to the height of your input images\n",
        "\n",
        "##### OPTIONAL: change these if needed\n",
        "how_many = 1830    # The number of images you wish to generate. Make sure this is greater than or equal to the number of images you're trying to generate\n",
        "which_epoch = 'latest' # The epoch you wish to generate images from (e.g. '20') (Defult: latest)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V73BNBbr_0R9"
      },
      "source": [
        "# Run this cell to generate your images. This may take a few minutes.\n",
        "!python test.py --name=$name --dataroot=$dataroot --checkpoints_dir checkpoints --results_dir=$results_dir --which_epoch=$which_epoch --how_many=$how_many --no_instance --label_nc 0 --loadSize=$loadSize --fineSize=$fineSize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AITt0XwQr5yX"
      },
      "source": [
        "## 7. Creating videos from your generated images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIMtiI26BKVk"
      },
      "source": [
        "### 7a. Create video of your test input images\n",
        "_Thread your test_A images together into a video. If your input images used Canny Edge, then this will be a video of your Canny Edge inputs._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLTMmMolJa4Y"
      },
      "source": [
        "1. **-i**: the input images _(the filepath to your synthesized images)_\n",
        "1. **-r**: the framerate _(any value between 1-60)_\n",
        "1. **-crf**: the compression quality of the output video _(lower is better, 17-25 is a good range)_\n",
        "1. **_the output filename_**: the last argument; make sure to set this each time you create a new video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkEOfx5sJ6z"
      },
      "source": [
        "# change experiment_name, dataset_name, and 'input_images_sequence.mp4'\n",
        "!ffmpeg \\\n",
        "   -pattern_type glob \\\n",
        "   -i \"./results/experiment_name/dataset_name/test_latest/images/*_input_label.png\" \\\n",
        "   -r 30 \\\n",
        "   -vcodec libx264 \\\n",
        "   -crf 23 \\\n",
        "   -pix_fmt yuv420p \\\n",
        "   ./generated_videos/input_images_sequence.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X7A6HUsBXx6"
      },
      "source": [
        "### 7b. Create video of your synthesized images\n",
        "_Thread your synthesized images together into a video._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoDrHlPaJOpC"
      },
      "source": [
        "1. **-i**: the input images _(the filepath to your synthesized images)_\n",
        "1. **-r**: the framerate _(any value between 1-60)_\n",
        "1. **-crf**: the compression quality of the output video _(lower is better, 17-25 is a good range)_\n",
        "1. **_the output filename_**: the last argument; make sure to set this each time you create a new video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwZDYXvSBdS6"
      },
      "source": [
        "# change experiment_name, dataset_name, and 'synthesized_output.mp4'\n",
        "!ffmpeg \\\n",
        "   -pattern_type glob \\\n",
        "   -i \"./results/experiment_name/dataset_name/test_latest/images/*synthesized_image.png\" \\\n",
        "   -r 30 \\\n",
        "   -vcodec libx264 \\\n",
        "   -crf 23 \\\n",
        "   -pix_fmt yuv420p \\\n",
        "   ./generated_videos/synthesized_output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
